# Defense-against-Adversarial-Malware-using-RObust-Classifier (DAM-ROC)

**[Folder structure](#folder-structure)**
| **[Requirements](#requirements)**
| **[Example usage](#example-usage)**
| **[Reproduce results from paper](#reproduce-results-from-paper)**
| **[Pre-trained models](https://www.dropbox.com/s/tfwrfxknwbx8ars/damroc_pre-trained_models.zip)**
| **[Paper](https://www.google.com/search?q=temp+link&oq=temp+link&aqs=chrome..69i57j0i512l4j0i22i30j0i10i22i30j0i22i30l3.1807j0j7&sourceid=chrome&ie=UTF-8)**
| **[Citing](#citing)**

To develop a secure learning framework entitled, Defense against Adversarial Malware using RObust Classifier (DAM-ROC). The objective is to shield anti-malware entities against evasion attacks by making use of an adaptive adversarial training framework with novel retraining sample selector, (DAM-ROC OR) for Deep Neural Networks (DNN) based learners. Usage of Bayesian Neural Networks (BNN) along with possible quantification of predictive uncertainties is adapted. This generic framework, DAM-ROC is evaluated on benchmarked Android and Windows datasets to explore necessary trade-off between performance and robustness. DAM-ROC models are retrained to defend against gradient attacks like rBIMk, dBIMk, GRAMS and JSMA.

---

## Folder structure

```
├── DNN / BNN (moped, plain and avuc) learners
│   ├── output (generated on execution)
│   │   ├── metrics
│   |   │   ├── derived_results/*.json
│   |   │   ├── normal_results/*.json
│   │   ├── trained_models/*.pt(h)
│   │   ├── tables
│   ├── ...
│   ├── create_tables.py
│   ├── framework.py
│   ├── run_experiments.py
│   ├── parameters.ini
├── helper_files
│   ├── sample_dataset
│   │   ├── mal/*.pt
│   │   ├── ben/*.pt
│   ├── ...
│   ├── linux_environment.yml
│   ├── osx_environment.yml
├── README.md
```

---

## Requirements

- pytorch (1.10.2)
- numpy (1.19.2)
- pandas (1.1.5)
- pybloomfiltermmap (0.3.15)
- losswise (4.0)
- sklearn (0.24.2)
- matplotlib (3.3.4)
- lief (0.12.1)

The code is built using **Python 3.6.13**

All the required packages are specified in the yml files under `helper_files` folder in the root directory. If `conda` is installed, `cd` to the root directory and execute the following with `osx_environment.yml` or `linux_environment.yml` on OSx or Linux, respectively.

_Linux_

```
conda env create --file ./helper_files/linux_environment.yml
```

_OSx_

```
conda env create --file ./helper_files/osx_environment.yml
```

This will create an environment called `damroc`.

To activate this environment, execute the following command:

```
conda activate damroc
```

**Note:** Windows OS doesn't support _pybloomfiltermmap_ out of the box. The workaround for this is to install another package using pip (`pip install dm-pybloom`). After the installation, make the necessary changes in _covering_number.py_ file inside _dnn->blindspot_coverage_. Change the import statement to `from pybloom import BloomFilter` and remove _pybloomfilter_. Also, make sure CUDA version of pytorch is installed in windows.

---

## Example usage

### Train / Test natural model

1. Configure the experiment as desired by modifying the `parameters.ini` file present inside a learner. Some of the parameters to modify are:

   - dataset filepath
   - gpu device if any
   - name of the experiment
   - training method (inner maximizer)
   - evasion method
   - other hyperparameters

   <br>

   After configuring the dataset filepath and other hyperparams, set the training method to `natural`. To test the natural model with different attacks or no attack, set the evasion methon parameter to one of the following - `natural`, `dfgsm_k`, `rfgsm_k`, `topkr` or `grosse`.

   **Note** A dataset with 100 malware and 100 benign samples is provided for testing purposes. This is present in the `helper_files` folder in the root directory.

2. Execute `framework.py`

   ```
   python framework.py
   ```

---

### Train / Test using DAM-ROC defense

To use the DAM-ROC retraining sample selector, modify the training method param in `parameters.ini` to any of the available attacks.

The available attacks are,

- natural
- dfgsm_k (aka dBIMk)
- rfgsm_k (aka rBIMk)
- topkr (aka GRAMS)
- grosse (aka JSMA)

When an attack is specified, the code uses the DAM-ROC selector by default and trains the model with the given dataset and hyperparameters.

---

## Reproduce results from paper

In order to reproduce the results in the paper, set the parameters accordingly and execute `run_experiments.py` script. This script runs the framework for all combinations of training and evasion and stores the results.

```
python run_experiments.py
```

Results (metrics and retrained models) will be populated under `output` directory inside the chosen learner directory (dnn, bnn and its variants).

To create csv tables from the obtained results, use `create_tables.py` file in the learner directory. Some of the variables that can be modified are - _**train_methods, evasion_methods**_ and _**metric**_.

```
python create_tables.py
```

The generated table is saved in the `output/tables` directory.

---

## Citing

To be added
